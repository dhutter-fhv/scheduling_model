{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# implementation according to https://link.springer.com/content/pdf/10.1007/s40092-017-0204-z.pdf\n",
    "import copy\n",
    "import pygad\n",
    "from hybrid_solution_data_loader import get_data\n",
    "import random\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Environment Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Worst possible schedule duration: 130\n"
     ]
    }
   ],
   "source": [
    "# NOTE 1: in this dataset, all jobs can be processed on any workstation\n",
    "# NOTE 2: Assuming every recipe is ordered exactly once\n",
    "n_workstations, recipes, operation_times = get_data(0) # 0-3\n",
    "worst_case = 0\n",
    "for operation in operation_times:\n",
    "    max = -float('inf')\n",
    "    for duration in operation:\n",
    "        if duration > max:\n",
    "            max = duration\n",
    "    worst_case += max\n",
    "print(f'Worst possible schedule duration: {worst_case}')\n",
    "last_slot = worst_case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(n_workstations, recipes, operation_times):\n",
    "    # assuming every recipe gets ordered exactly once with this dataset\n",
    "    input_format = [0 for _ in range(len(operation_times) * 2)]\n",
    "    orders = [i for i in range(len(recipes))]\n",
    "    return input_format, orders, None\n",
    "    \n",
    "def translate():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_format, orders, instance = read_data(n_workstations, recipes, operation_times)\n",
    "# skip translation into own format for now\n",
    "#recipes, workstations, resources, tasks, orders_model = translate(instance, orders)\n",
    "#env = SimulationEnvironment(workstations, tasks, resources, recipes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_task_for_job(index): # needed?\n",
    "    return 0 # TODO\n",
    "\n",
    "def operation_index_to_recipe(index):\n",
    "    operation_sum = 0\n",
    "    for i in range(len(recipes)):\n",
    "        if operation_sum + recipes[i] > index:\n",
    "            return i\n",
    "        else:\n",
    "            operation_sum += recipes[i]\n",
    "    return -1\n",
    "\n",
    "def similarity(a, b):\n",
    "    # used encoding: <assignments, sequence> \n",
    "    distance = 0\n",
    "    pivot = int(len(a)/2)\n",
    "    for i in range(0, pivot):\n",
    "        if a[i] != b[i]: # workstation assignment\n",
    "            distance += len(n_workstations) # get amount of alternative workstations for the respective job\n",
    "        if a[pivot+i] != b[pivot+i]: # job sequence\n",
    "            distance += 1 \n",
    "    return distance\n",
    "\n",
    "def validate_sequence(individual, order_job_amounts):\n",
    "    counted = copy.deepcopy(order_job_amounts)\n",
    "    for i in range(len(individual)/2, len(individual)):\n",
    "        counted[individual[i]] -= 1\n",
    "    return all(x == 0 for x in counted)\n",
    "\n",
    "def validate_assignments(individual):\n",
    "    return all(individual[i] < n_workstations and individual[i] >= 0 for i in range(len(individual)/2))\n",
    "\n",
    "def construct_schedule(individual):\n",
    "    # for each job:\n",
    "    # check if job is first for it's order\n",
    "    # start_o = 0\n",
    "    # else\n",
    "    # start_o = end of previous job for order\n",
    "    # check if job is first on workstation\n",
    "    # start_w = 0\n",
    "    # else\n",
    "    \"\"\"# check for gaps between previous jobs on workstations (between end of previous job and start_o)\n",
    "    # if any gap is big enough\n",
    "    # start_w = end of job prior to gap\n",
    "    # else\"\"\" # shouldn't be necessary\n",
    "    # start_w = end of previous job on workstation\n",
    "    # set start point as max(start_o, start_w)\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1 - GA: global exploration to find promising areas in the search space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mutation_function(offsprings, ga_instance):\n",
    "    # randomly choose new alternative workstation for assignments\n",
    "    # randomly switch order for sequence\n",
    "    pass\n",
    "\n",
    "def crossover_function(parents, offspring_size, ga_instance):\n",
    "    # uniform crossover for assignments\n",
    "    parent1 = parents[0].copy()\n",
    "    parent2 = parents[1].copy()\n",
    "    offspring_assignemnts = []\n",
    "    for i in range(len(operation_times)): # assumption that every recipe is ordered exactly once\n",
    "        if random.random() < 0.5:\n",
    "            offspring_assignemnts.append(parent1[i])\n",
    "        else:\n",
    "            offspring_assignemnts.append(parent2[i])\n",
    "    offspring_sequence = []\n",
    "    # iPOX crossover for sequence\n",
    "    for i in range(len(operation_times) / 2, 2 * len(operation_times)): # assumption that every recipe is ordered exactly once\n",
    "        pass\n",
    "    # -> select parents\n",
    "    # -> randomly generate 2 job subsets\n",
    "    # -> copy genes belonging to the jobs in the subsets\n",
    "    # -> fill in the gaps in order with the rest\n",
    "    offspring = np.concatenate([offspring_assignemnts, offspring_sequence]) # concats 2 python arrays, returns np array\n",
    "    return offspring\n",
    "\n",
    "def selection_function(fitness, num_parents, ga_instance):\n",
    "    fitness_sorted = sorted(range(len(fitness)), key=lambda k: fitness[k])\n",
    "    fitness_sorted.reverse()\n",
    "\n",
    "    parents = np.empty((num_parents, ga_instance.population.shape[1]))\n",
    "    # for each individual \n",
    "    # FN = sum ( 1 / (Cmax(individual) * neighbourhood) )\n",
    "    # \n",
    "    # selection_probability_k = ( 1 / (Cmax(individual) * neighbourhood) ) / FN # selection probability for each individual\n",
    "    return parents, fitness_sorted[:num_parents] # replace with actual fitness of chosen parents\n",
    "\n",
    "def fitness_function(solution, solution_idx):\n",
    "    if validate_sequence(None, None) and validate_assignments(None, None):\n",
    "        # feasible solution\n",
    "        # 1 / Cmax(individual) #\n",
    "        pass\n",
    "    else:\n",
    "        # infeasible solution\n",
    "        pass\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks_jobs = [] # list of tasks in order for lookups with the job id\n",
    "assignments = []\n",
    "sequence = []\n",
    "\n",
    "num_generations = 1000\n",
    "num_parents_mating = 50\n",
    "sol_per_pop = 100\n",
    "init_range_low = 0\n",
    "init_range_high = len(orders) # doesn't really matter\n",
    "keep_parents = 10\n",
    "mutation_percent_genes = 10 # doesn't really matter\n",
    "\n",
    "crossover_type = crossover_function\n",
    "mutation_type = mutation_function\n",
    "fitness_func = fitness_function\n",
    "parent_selection_type = selection_function\n",
    "\n",
    "num_genes = len(input_format) * 2\n",
    "gene_type = int\n",
    "gene_space = []\n",
    "\n",
    "for i in range(num_genes / 2):\n",
    "    # set space for the first half (assignments)\n",
    "    gene_space.append(len(n_workstations))\n",
    "for i in range(num_genes / 2, num_genes):\n",
    "    # set space for the second half (sequence)\n",
    "    gene_space.append(len(orders))\n",
    "\n",
    "ga_instance = pygad.GA(num_generations=num_generations, num_parents_mating=num_parents_mating, fitness_func=fitness_func, sol_per_pop=sol_per_pop, num_genes=num_genes, init_range_low=init_range_low, init_range_high=init_range_high, parent_selection_type=parent_selection_type, keep_parents=keep_parents, crossover_type=crossover_type, mutation_type=mutation_type, mutation_percent_genes=mutation_percent_genes, gene_type=gene_type, gene_space=gene_space)\n",
    "ga_instance.run()\n",
    "solution, solution_fitness, solution_idx = ga_instance.best_solution()\n",
    "print(\"Parameters of the best solution : {solution}\".format(solution=solution))\n",
    "print(\"Fitness value of the best solution = {solution_fitness}\".format(solution_fitness=abs(solution_fitness) - 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Intermediate Step: Clustering of the final GA population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2 - Tabu Search: find best individual solutions through local searches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_neighbours(individual):\n",
    "    pass\n",
    "\n",
    "def calculate_fitness(individual):\n",
    "    pass\n",
    "\n",
    "def search(individuals):\n",
    "    best = individuals[0]\n",
    "    max_tabu_size = int(len(individuals) / 4) # for testing\n",
    "    best_candidate = individuals[0]\n",
    "    best_fitness = best_candidate_fitness = calculate_fitness(best_candidate)\n",
    "    tabu_list = []\n",
    "    tabu_list.append(individuals[0])\n",
    "    stop = False\n",
    "    max_iter = 1000\n",
    "    i = 0\n",
    "    while not stop:\n",
    "        neighbours = get_neighbours(best_candidate)\n",
    "        best_candidate = neighbours[0]\n",
    "        for candidate in neighbours:\n",
    "            if candidate not in tabu_list:\n",
    "                candidate_fitness = calculate_fitness(candidate)\n",
    "                if candidate_fitness < best_candidate_fitness:\n",
    "                    best_candidate = candidate\n",
    "                    best_candidate_fitness = candidate_fitness\n",
    "        if best_candidate_fitness < best_fitness:\n",
    "            best = best_candidate\n",
    "            best_fitness = best_candidate_fitness\n",
    "        tabu_list.append(best_candidate)\n",
    "        if len(tabu_list) > max_tabu_size:\n",
    "            tabu_list.pop()\n",
    "        stop = i >= max_iter\n",
    "        i+=1\n",
    "    return best"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7f6a1dc8c4280d136ecdbc82017e55b6ce3aee96b85e53655c8afc2236474583"
  },
  "kernelspec": {
   "display_name": "Python 3.10.3 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
