{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pygad\n",
    "import random\n",
    "from read_data import read_dataset_1, translate_1, read_dataset_3, translate_3, translate_1_testing\n",
    "from models import SimulationEnvironment\n",
    "from optimizer_components import map_index_to_operation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "order_amount = 5\n",
    "earliest_time_slot = 0\n",
    "last_time_slot = 5000 # shouldn't actually be necessary for this"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "input, orders, instance = read_dataset_1(use_instance=13, order_amount=order_amount, earliest_time=earliest_time_slot, last_time=last_time_slot)\n",
    "#recipes, workstations, resources, tasks, orders_model = translate_1(instance, orders, earliest_time_slot, last_time_slot)\n",
    "recipes, workstations, resources, tasks, orders_model = translate_1_testing(instance, orders, earliest_time_slot, last_time_slot)\n",
    "#input, orders, instance = read_dataset_3(order_amount, earliest_time_slot, last_time_slot)\n",
    "#recipes, workstations, resources, tasks, orders_model = translate_3(instance, 10, orders)\n",
    "env = SimulationEnvironment(workstations, tasks, resources, recipes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "assignments = []\n",
    "start_times = []\n",
    "\n",
    "\"\"\"duration_lookup_table = dict()\n",
    "for task in tasks:\n",
    "    if not task.id in duration_lookup_table:\n",
    "            duration_lookup_table[task.id] = dict()\n",
    "    for workstation in env.get_valid_workstations(task.id):\n",
    "        duration_lookup_table[task.id][workstation.id] = env.get_duration(task.id, workstation.id)\"\"\"\n",
    "duration_lookup_table = dict()\n",
    "for task in tasks:\n",
    "    if not task.external_id in duration_lookup_table:\n",
    "            duration_lookup_table[task.external_id] = dict()\n",
    "    for workstation in env.get_valid_workstations(task.external_id):\n",
    "        duration_lookup_table[task.external_id][workstation.id] = env.get_duration(task.external_id, workstation.id)\n",
    "\n",
    "operations = []\n",
    "order_for_index = []\n",
    "for order in orders_model:\n",
    "    for resource in order.resources:\n",
    "        recipe = resource.recipes[0] # just use recipe 0 for now\n",
    "        recipe_tasks = env.get_all_tasks_for_recipe(recipe.id)\n",
    "        results = dict()\n",
    "        for task in recipe_tasks:\n",
    "            if task.result_resources[0][0] not in results:\n",
    "                results[task.result_resources[0][0]] = []\n",
    "            results[task.result_resources[0][0]].append(task)\n",
    "        for key in results:\n",
    "            #operations.append(random.choice(results[key]).id)\n",
    "            operations.append(random.choice(results[key]).external_id)\n",
    "            order_for_index.append(order.id)\n",
    "\n",
    "for operation in operations:\n",
    "    workstation = env.get_valid_workstations(operation)\n",
    "    # random init\n",
    "    assignments.append(random.choice(workstation).id)\n",
    "    assignments.append(0) # start time slot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: {1: 123, 2: 132}, 1: {4: 140, 7: 123}, 2: {7: 170, 5: 120}, 3: {5: 120, 3: 125}, 4: {3: 87}, 5: {3: 178, 6: 95}, 6: {6: 87}, 7: {6: 190}, 8: {6: 190}, 9: {6: 66}, 10: {6: 250}, 11: {6: 165}, 12: {6: 123}, 13: {6: 86}, 14: {6: 110}, 15: {6: 115}, 16: {6: 150}, 17: {6: 120}, 18: {6: 145}, 19: {6: 124}, 20: {6: 160}}\n",
      "[6, 7, 8, 15, 16, 17, 15, 16, 17, 3, 4, 5, 6, 7, 8]\n"
     ]
    }
   ],
   "source": [
    "print(duration_lookup_table)\n",
    "print(operations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prev_scheduled_operations(individual, index): # TODO: double check orders\n",
    "    # return assignments + start times as list of tuples\n",
    "    id, target_order = map_index_to_operation(index, orders, env)\n",
    "    jobs = instance[1]\n",
    "    idx = 0\n",
    "    prev_scheduled = []\n",
    "    for order in orders:\n",
    "        for i in range(len(jobs[order[0]])): # amount of necessary operations for job n\n",
    "            if order[2] == target_order[2]:\n",
    "                prev_scheduled.append((individual[idx], individual[idx+1])) # double check\n",
    "            idx += 2\n",
    "    return prev_scheduled\n",
    "\n",
    "def calculate_start_time(individual):\n",
    "    i = 0\n",
    "    operation_index = 0\n",
    "    for idx in range(len(individual)):\n",
    "    #for gene in individual:\n",
    "        gene = individual[idx]\n",
    "        if i == 0:\n",
    "            on_workstation = 0 # find all assignments to the same workstation\n",
    "            prev_operations = [] # find all operations belonging to the same order, which need to be scheduled before the current operation\n",
    "            # calculate start time, aka choose max(last end time on workstation, last end time of previous sequenced operation for task)\n",
    "            k = 0\n",
    "            for j in range(idx): # introduces dependency on sequence of the orders\n",
    "                if k == 0:\n",
    "                    if individual[j] == gene:\n",
    "                        if individual[j+1] > on_workstation:\n",
    "                            on_workstation = individual[j+1]\n",
    "                k += 1\n",
    "                if k > 1:\n",
    "                    k = 0\n",
    "            prev_operations = get_prev_scheduled_operations(individual, idx)\n",
    "            prev_operation = max(prev_operations, key=lambda tup: tup[1])\n",
    "            individual[idx+1] = max(on_workstation, prev_operation[1])\n",
    "        i += 1\n",
    "        if i > 1:\n",
    "            i = 0\n",
    "            operation_index += 1\n",
    "    return individual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_colors(n): \n",
    "    ret = [] \n",
    "    r = int(random.random() * 256) \n",
    "    g = int(random.random() * 256) \n",
    "    b = int(random.random() * 256) \n",
    "    step = 256 / n \n",
    "    for i in range(n): \n",
    "        r += step \n",
    "        g += step \n",
    "        b += step \n",
    "        r = int(r) % 256 \n",
    "        g = int(g) % 256 \n",
    "        b = int(b) % 256 \n",
    "        ret.append((r,g,b))  \n",
    "    return ret\n",
    "\n",
    "def visualize(data):\n",
    "    # data format: 0 - workstation, 1 - job id, 2 - start time, 3 - duration\n",
    "    colors = {}\n",
    "    rgb_values = get_colors(len(orders))\n",
    "    for i in range(len(orders)):\n",
    "        colors[str(f'Order {i}')] = f'rgb({rgb_values[i][0]}, {rgb_values[i][1]}, {rgb_values[i][2]})' # just ignore colors for now\n",
    "    composed_data = []\n",
    "    \n",
    "    for i in range(len(data)):\n",
    "        label = f'W{data[i][0]}'\n",
    "        start = data[i][2]\n",
    "        end = start + data[i][3]\n",
    "        composed_data.append(\n",
    "                    dict(Task=label, Start=start, Finish=end, Resource=f'Order {order_for_index[i]}')\n",
    "                )\n",
    "        #print(composed_data)\n",
    "    fig = ff.create_gantt(composed_data, colors=colors, index_col='Resource', show_colorbar=True,\n",
    "                        group_tasks=True, showgrid_x=True)\n",
    "    fig.update_layout(xaxis_type='linear')\n",
    "    \"\"\"import plotly.express as px\n",
    "    fig = px.timeline(composed_data, x_start='Start', x_end='Finish', y='Task', color='Resource')\"\"\" # for some reason doesn't do what it's supposed to do\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GA Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mutation_function(offspring, ga_instance):\n",
    "    i = 0\n",
    "    operation_index = 0\n",
    "    p = 0.1#ga_instance.mutation_percent_genes\n",
    "    idx = 0\n",
    "    for gene in offspring:\n",
    "        if i == 0:\n",
    "            if random.random() < p:\n",
    "                # mutate\n",
    "                # according to paper, calc workload of each elligible workstation, switch to lowest workload\n",
    "                workload = []\n",
    "                valid_workstations = env.get_valid_workstations(operations[int(idx/2)]) # TODO: double check\n",
    "                for j in range(len(valid_workstations)): \n",
    "                    count = 0\n",
    "                    for k in range(0, gene, 2):\n",
    "                        if offspring[k] == valid_workstations[j].id:\n",
    "                            count += 1\n",
    "                    workload.append((valid_workstations[j], count))\n",
    "                current_count = 0\n",
    "                for t in workload:\n",
    "                    if t[0] == gene:\n",
    "                        current_count = t[1]\n",
    "                        break\n",
    "                # gather all workloads smaller than the current workstations workload\n",
    "                lower_loads = []\n",
    "                smallest_load = t\n",
    "                for t in workload:\n",
    "                    if t[0] != gene and t[1] < current_count:\n",
    "                        lower_loads.append(t)\n",
    "                        if t[1] < smallest_load[1]:\n",
    "                            smallest_load = t\n",
    "                #offspring[idx] = random.choice(lower_loads)[0] # choose random smaller workstation\n",
    "                offspring[idx] = smallest_load[0].id # just use smallest workload possible\n",
    "        i+=1\n",
    "        if i > 1:\n",
    "            i = 0\n",
    "            operation_index += 1\n",
    "        idx += 1\n",
    "    # re-calculate start times\n",
    "    calculate_start_time(offspring)\n",
    "    return offspring\n",
    "\n",
    "# make sure crossover is performed at workstation assignments\n",
    "def crossover_function(parents, offspring_size, ga_instance):\n",
    "    split_point = random.randint(0, len(assignments))\n",
    "    if split_point % 2 == 1:\n",
    "        split_point -= 1\n",
    "    parent1 = parents[0].copy()\n",
    "    parent2 = parents[1].copy()\n",
    "    offspring = []\n",
    "    for i in range(len(assignments)):\n",
    "        if i < split_point:\n",
    "            offspring.append(parent1[i])\n",
    "        else:\n",
    "            offspring.append(parent2[i])\n",
    "    return offspring\n",
    "\n",
    "def fitness_function(solution, solution_idx):\n",
    "    fitness = 1\n",
    "    i = 0\n",
    "    operation_index = 0\n",
    "    max = -float('inf')\n",
    "    min = float('inf')\n",
    "    for idx in range(len(solution)):\n",
    "        if i == 1:\n",
    "            start = solution[idx]\n",
    "            end = start + duration_lookup_table[operations[int((idx-1)/2)]][solution[idx-1]] # double check operations\n",
    "            if start < min:\n",
    "                min = start\n",
    "            if end > max:\n",
    "                max = end\n",
    "        i += 1\n",
    "        if i > 1:\n",
    "            i = 0\n",
    "            operation_index += 1\n",
    "    fitness = abs(max - min)\n",
    "    return -fitness\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\huda\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pygad\\pygad.py:486: UserWarning: The percentage of genes to mutate (mutation_percent_genes=1) resutled in selecting (0) genes. The number of genes to mutate is set to 1 (mutation_num_genes=1).\n",
      "If you do not want to mutate any gene, please set mutation_type=None.\n",
      "  if not self.suppress_warnings: warnings.warn(\"The percentage of genes to mutate (mutation_percent_genes={mutation_percent}) resutled in selecting ({mutation_num}) genes. The number of genes to mutate is set to 1 (mutation_num_genes=1).\\nIf you do not want to mutate any gene, please set mutation_type=None.\".format(mutation_percent=mutation_percent_genes, mutation_num=mutation_num_genes))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters of the best solution : [   6 4548    6 4548    6 4548    6 4548    6 4548    6 4548    6 4548\n",
      "    6 4548    6 4548    3 4548    3 4548    6 4548    6 4548    6 4548\n",
      "    6 4548]\n",
      "Fitness value of the best solution = 189\n"
     ]
    }
   ],
   "source": [
    "num_genes = len(assignments)\n",
    "num_generations = 5000\n",
    "num_parents_mating = 50\n",
    "sol_per_pop = 100\n",
    "init_range_low = 0\n",
    "init_range_high = last_time_slot\n",
    "parent_selection_type = 'rws'\n",
    "keep_parents = 10\n",
    "crossover_type = crossover_function\n",
    "mutation_type = mutation_function\n",
    "mutation_percentage_genes = 1#0.1\n",
    "fitness_func = fitness_function\n",
    "gene_type = int\n",
    "space_workstations = {'low': 0, 'high': len(workstations)-1} #0?\n",
    "space_time = {'low': 0, 'high': last_time_slot}\n",
    "gene_space = []\n",
    "i = 0\n",
    "for j in range(len(assignments)):\n",
    "    if i == 0:\n",
    "        valid_workstations = env.get_valid_workstations(operations[int(j/2)])\n",
    "        space = []\n",
    "        for k in range(len(valid_workstations)):\n",
    "            space.append(valid_workstations[k].id)\n",
    "        gene_space.append(space)\n",
    "    else:\n",
    "        gene_space.append(space_time) # shouldn't be needed because of manual mutation and crossover\n",
    "    i += 1\n",
    "    if i > 1:\n",
    "        i = 0\n",
    "ga_instance = pygad.GA(num_generations=num_generations, num_parents_mating=num_parents_mating, fitness_func=fitness_func, sol_per_pop=sol_per_pop, num_genes=num_genes, init_range_low=init_range_low, init_range_high=init_range_high, parent_selection_type=parent_selection_type, keep_parents=keep_parents, crossover_type=crossover_type, mutation_type=mutation_type, mutation_percent_genes=mutation_percentage_genes, gene_type=gene_type, gene_space=gene_space)\n",
    "ga_instance.run()\n",
    "solution, solution_fitness, solution_idx = ga_instance.best_solution()\n",
    "\n",
    "print(\"Parameters of the best solution : {solution}\".format(solution=solution))\n",
    "print(\"Fitness value of the best solution = {solution_fitness}\".format(solution_fitness=abs(solution_fitness) - 1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.3 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1e478315ea93f9f083d422a59179b37c6ead09cc57c0e51f656bb4b8796d5f86"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
