{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from translation import FJSSPInstancesTranslator, SequenceGAEncoder\n",
    "from model import ProductionEnvironment, Order\n",
    "import pandas as pd\n",
    "\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lit_path = r'C:\\Users\\huda\\Documents\\GitHub\\scheduling_model\\code\\reworked_data_model\\results\\lit_results\\lit_best_known.csv'\n",
    "ga_path = r'C:\\Users\\huda\\Downloads\\newest\\newest\\\\'\n",
    "files = ['s0_s1_3600.txt','s4_3600.txt','s5_s6_s3_3600.txt', 's2a_3600.txt', 's2b_3600.txt', 's2c_s2d_3600.txt', 'behnke_geiger_repeat.txt', 'chambers.txt', 'dppaulli.txt', 'fattahi.txt', 'behnkegeiger.txt', 'brandimarte.txt']\n",
    "\n",
    "gurobi_30 = r'C:\\Users\\huda\\Documents\\GitHub\\scheduling_model\\code\\reworked_data_model\\results\\gurobi_results\\formatted_results\\30_min.txt'\n",
    "gurobi_60 = r'C:\\Users\\huda\\Documents\\GitHub\\scheduling_model\\code\\reworked_data_model\\results\\gurobi_results\\formatted_results\\60_min.txt'\n",
    "\n",
    "benchmark_base_path = r'C:\\Users\\huda\\Documents\\GitHub\\scheduling_model\\code\\external_test_data\\FJSSPinstances\\\\'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "include_sdata = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_one_order_per_recipe(production_environment : ProductionEnvironment) -> list[Order]:\n",
    "    orders : list[Order] = []\n",
    "    for i in range(len(production_environment.resources.values())): # should be the same amount as recipes for now\n",
    "        orders.append(Order(delivery_time=1000, latest_acceptable_time=1000, resources=[(production_environment.get_resource(i), 1)], penalty=100.0, tardiness_fee=50.0, divisible=False, profit=500.0))\n",
    "    return orders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_benchmark_file(source, instance):\n",
    "    if source.startswith('0'):\n",
    "        target_file = f'Behnke{instance}.fjs'\n",
    "    elif source.startswith('1'):\n",
    "        target_file = f'BrandimarteMk{instance}.fjs'\n",
    "    elif source.startswith('2a'):\n",
    "        target_file = f'HurinkSdata{instance}.fjs'\n",
    "    elif source.startswith('2b'):\n",
    "        target_file = f'HurinkEdata{instance}.fjs'\n",
    "    elif source.startswith('2c'):\n",
    "        target_file = f'HurinkRdata{instance}.fjs'\n",
    "    elif source.startswith('2d'):\n",
    "        target_file = f'HurinkVdata{instance}.fjs'\n",
    "    elif source.startswith('3'):\n",
    "        target_file = f'DPpaulli{instance}.fjs'\n",
    "    elif source.startswith('4'):\n",
    "        target_file = f'ChambersBarnes{instance}.fjs'\n",
    "    elif source.startswith('5'):\n",
    "        target_file = f'Kacem{instance}.fjs'\n",
    "    elif source.startswith('6'):\n",
    "        target_file = f'Fattahi{instance}.fjs'\n",
    "    path = benchmark_base_path + f'{source}\\\\{target_file}'\n",
    "    return open(path, 'r').readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_benchmark_data(content):   \n",
    "    line = dict()\n",
    "    line['source'] = content[0]\n",
    "    line['instance'] = int(content[1])\n",
    "\n",
    "    # add information about the benchmark instance\n",
    "    benchmark_file = read_benchmark_file(line['source'], line['instance'])\n",
    "    benchmark_system = benchmark_file[0].split(' ')\n",
    "    line['n_machines'] = int(benchmark_system[1])\n",
    "    line['n_jobs'] = int(benchmark_system[0])\n",
    "    line['average_workstations_per_operation'] = float(benchmark_system[2])\n",
    "    jobs = benchmark_file[1:]\n",
    "    line['n_operations'] = sum([int(x.split(' ')[0]) for x in jobs])\n",
    "    line['average_operations_per_job'] = line['n_operations'] / line['n_jobs']\n",
    "    line['beta_flexibility'] = line['average_workstations_per_operation']/line['n_machines']\n",
    "    line['approximate_max_dissimilarity'] = line['n_operations'] + line['average_operations_per_job'] * line['average_workstations_per_operation']\n",
    "\n",
    "    production_environment = FJSSPInstancesTranslator().translate(line['source'], line['instance'])\n",
    "    orders = generate_one_order_per_recipe(production_environment)\n",
    "    production_environment.orders = orders\n",
    "    workstations_per_operation, base_durations, job_operations = SequenceGAEncoder().encode(production_environment, orders)\n",
    "    unique_durations = []\n",
    "    overall_amount_durations = []\n",
    "    for duration in base_durations:\n",
    "        for d in duration:\n",
    "            if d not in unique_durations and d > 0:\n",
    "                unique_durations.append(d)\n",
    "        overall_amount_durations.extend([x for x in duration if x > 0])\n",
    "    overall_amount_durations = len(overall_amount_durations)\n",
    "    line['duration_variety'] = (len(unique_durations)/overall_amount_durations)\n",
    "    return line    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dict()\n",
    "benchmark_data = []\n",
    "for file in files:\n",
    "    content = open(ga_path + file, 'r').readlines()\n",
    "    for values in content:\n",
    "        line = values.split(';')\n",
    "\n",
    "        uid = line[0]+line[1]\n",
    "        if include_sdata or not uid.startswith('2a'):\n",
    "            if uid not in data:\n",
    "                data[uid] = [float(line[6])]\n",
    "            elif data[uid][0] > float(line[6]):\n",
    "                data[uid] = [float(line[6])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "content = open(lit_path, 'r').readlines()\n",
    "for values in content[1:]:\n",
    "    line = values.split(';')\n",
    "    uid = line[0]+line[1]\n",
    "    #if not any([x['source'] == line[0] and x['instance'] == line[1] for x in benchmark_data]):\n",
    "    benchmark_data.append(load_benchmark_data(line))\n",
    "    if include_sdata or not uid.startswith('2a'):\n",
    "        if uid in data: # skip remaining benchmarks\n",
    "            value = float(line[3])\n",
    "            if value < 0:\n",
    "                value = 10000000 # replacing missing data\n",
    "            data[uid].append(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "content = open(gurobi_30, 'r').readlines()\n",
    "for values in content[1:]:\n",
    "    line = values.split(';')\n",
    "    uid = line[0]+line[1]\n",
    "    if include_sdata or not uid.startswith('2a'):\n",
    "        if uid in data: # skip remaining benchmarks\n",
    "            data[uid].append(int(float(line[2]) + 0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "content = open(gurobi_60, 'r').readlines()\n",
    "for values in content[1:]:\n",
    "    line = values.split(';')\n",
    "    uid = line[0]+line[1]\n",
    "    if include_sdata or not uid.startswith('2a'):\n",
    "        if uid in data: # skip remaining benchmarks\n",
    "            data[uid][2] = (int(float(line[2]) + 0.5)) # assuming 60 min is better than the 30 min result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_gap(best, value):\n",
    "    return (value - best)/best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2', '29']\n",
      "['a', '_', 'H', 'u', 'r', 'i', 'n', 'k', '_', 's', 'd', 'a', 't', 'a']\n"
     ]
    }
   ],
   "source": [
    "example = '2a_Hurink_sdata29'\n",
    "numbers = re.findall(r'\\d+', example)\n",
    "source = re.findall(r'[^\\d+]', example)\n",
    "print(numbers)\n",
    "print(source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmarks = dict()\n",
    "mapping = dict()\n",
    "for key in data.keys():\n",
    "    numbers = re.findall(r'\\d+', key)\n",
    "    rest = re.findall(r'[^\\d+]', key)\n",
    "    sId = int(numbers[0])\n",
    "    source = ''\n",
    "    if sId == 0:\n",
    "        source = '0_BehnkeGeiger'\n",
    "    elif sId == 1:\n",
    "        source = '1_Brandimarte'\n",
    "    elif sId == 2:\n",
    "        if rest[0] == 'a':\n",
    "            source = '2a_Hurink_sdata'\n",
    "        elif rest[0] == 'b':\n",
    "            source = '2b_Hurink_edata'\n",
    "        elif rest[0] == 'c':\n",
    "            source = '2c_Hurink_rdata'\n",
    "        else:\n",
    "            source = '2d_Hurink_vdata'\n",
    "    elif sId == 3:\n",
    "        source = '3_DPpaulli'\n",
    "    elif sId == 4:\n",
    "        source = '4_ChambersBarnes'\n",
    "    elif sId == 5:\n",
    "        source = '5_Kacem'\n",
    "    else:\n",
    "        source = '6_Fattahi'\n",
    "    instance = int(numbers[1])\n",
    "    benchmarks[key] = load_benchmark_data(read_benchmark_file(source, instance))\n",
    "    mapping[key] = (source, instance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: 0 - GA, 1 - Lit, 2 - Gurobi\n",
    "best = dict()\n",
    "for key in data.keys():\n",
    "    best[key] = min(data[key])\n",
    "lit = dict()\n",
    "for key in data.keys():\n",
    "    lit[key] = data[1]\n",
    "gaps_lit = dict()\n",
    "for key in best.keys():\n",
    "    gaps_lit[key] = dict()\n",
    "    gaps_lit[key]['GA'] = (calc_gap(lit[key], data[key][0])) # GA\n",
    "    #gaps_lit[key]['Literature'] = (calc_gap(lit[key], data[key][1])) # Lit\n",
    "    gaps_lit[key]['Gurobi'] = (calc_gap(lit[key], data[key][2])) # Gurobi\n",
    "gaps = dict()\n",
    "for key in best.keys():\n",
    "    gaps[key] = dict()\n",
    "    gaps[key]['GA'] = (calc_gap(best[key], data[key][0])) # GA\n",
    "    gaps[key]['Literature'] = (calc_gap(best[key], data[key][1])) # Lit\n",
    "    gaps[key]['Gurobi'] = (calc_gap(best[key], data[key][2])) # Gurobi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_for_df = []\n",
    "for key in data.keys():\n",
    "    data_for_df.append({\n",
    "        'Source': mapping[0],\n",
    "        'Instance': mapping[1],\n",
    "        'GA': data[0],\n",
    "        'Gurobi': data[2],\n",
    "        'Literature': data[1],\n",
    "        'GA Best Gap': gaps[key]['GA'],\n",
    "        'Gurobi Best Gap': gaps[key]['Gurobi'],\n",
    "        'Literature Best Gap': gaps[key]['Literature'],\n",
    "        'GA Literature Gap': gaps_lit[key]['GA'],\n",
    "        'Gurobi Literature Gap': gaps_lit[key]['Gurobi'],\n",
    "        'GA/Gurobi': '+' if data[0] < data[2] else 'o' if data[0] == data[2] else '-',\n",
    "        'GA/Literature': '+' if data[0] < data[1] else 'o' if data[0] == data[1] else '-',\n",
    "        'n_machines': benchmarks[key]['n_machines'],\n",
    "        'n_operations': benchmarks[key]['n_operations'],\n",
    "        'beta_flexibility': benchmarks[key]['beta_flexibility'],\n",
    "        'duration_variety': benchmarks[key]['duration_variety']\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data_for_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('all_results.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
