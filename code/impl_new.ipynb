{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pygad\n",
    "import random\n",
    "from hybrid_solution_data_loader import get_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(n_workstatoins, recipes, operation_times):\n",
    "    pass\n",
    "\n",
    "def to_input(operations_times, recipes):\n",
    "    input_format = [0 for _ in range(len(operation_times) * 2)]\n",
    "    orders = [i for i in range(len(recipes))]\n",
    "    return input_format, orders, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_workstations, recipes, operation_times = get_data(0) # note: every task can be processed on all workstations in this dataset\n",
    "worst_case = 0\n",
    "for operation in operation_times:\n",
    "    max = -float('inf')\n",
    "    for duration in operation:\n",
    "        if duration > max:\n",
    "            max = duration\n",
    "    worst_case += max\n",
    "print(f'Worst possible schedule duration: {worst_case}')\n",
    "last_slot = worst_case\n",
    "translate(n_workstations, recipes, operation_times)\n",
    "to_input(operations_times, recipes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similarity(a, b):\n",
    "    # used encoding: <assignments, sequence> \n",
    "    distance = 0\n",
    "    pivot = int(len(a)/2)\n",
    "    for i in range(0, pivot):\n",
    "        if a[i] != b[i]: # workstation assignment\n",
    "            distance += len(n_workstations) # get amount of alternative workstations for the respective job\n",
    "        if a[pivot+i] != b[pivot+i]: # job sequence\n",
    "            distance += 1 \n",
    "    return distance\n",
    "\n",
    "def validate_sequence(individual, order_job_amounts):\n",
    "    counted = copy.deepcopy(order_job_amounts)\n",
    "    for i in range(len(individual)/2, len(individual)):\n",
    "        counted[individual[i]] -= 1\n",
    "    return all(x == 0 for x in counted)\n",
    "\n",
    "def validate_assignments(individual):\n",
    "    return all(individual[i] < n_workstations and individual[i] >= 0 for i in range(len(individual)/2))\n",
    "\n",
    "def construct_schedule(individual):\n",
    "    # for each job:\n",
    "    # check if job is first for it's order\n",
    "    # start_o = 0\n",
    "    # else\n",
    "    # start_o = end of previous job for order\n",
    "    # check if job is first on workstation\n",
    "    # start_w = 0\n",
    "    # else\n",
    "    # start_w = end of previous job on workstation\n",
    "    # set start point as max(start_o, start_w)\n",
    "    pass\n",
    "\n",
    "def crossover_function(parents, offspring_size, ga_instance):\n",
    "    # uniform crossover for assignments\n",
    "    parent1 = parents[0].copy()\n",
    "    parent2 = parents[1].copy()\n",
    "    offspring_assignemnts = []\n",
    "    for i in range(len(operation_times)): # assumption that every recipe is ordered exactly once\n",
    "        if random.random() < 0.5:\n",
    "            offspring_assignemnts.append(parent1[i])\n",
    "        else:\n",
    "            offspring_assignemnts.append(parent2[i])\n",
    "    offspring_sequence = []\n",
    "    # iPOX crossover for sequence\n",
    "    for i in range(len(operation_times), 2 * len(operation_times)): # assumption that every recipe is ordered exactly once\n",
    "        pass\n",
    "    # -> select parent\n",
    "    # -> randomly generate 2 job subsets\n",
    "    # -> copy genes belonging to the jobs in the subsets\n",
    "    # -> fill in the gaps in order with the rest\n",
    "    offspring = np.concatenate([offspring_assignemnts, offspring_sequence]) # concats 2 python arrays, returns np array\n",
    "    return offspring\n",
    "\n",
    "def selection_function(fitness, num_parents, ga_instance):\n",
    "    fitness_sorted = sorted(range(len(fitness)), key=lambda k: fitness[k])\n",
    "    fitness_sorted.reverse()\n",
    "\n",
    "    parents = np.empty((num_parents, ga_instance.population.shape[1]))\n",
    "    # for each individual\n",
    "    # FN = sum ( 1 / (c_max(individual) * neighbourhood) )\n",
    "    # selection_probability_k = ( 1 / (c_max(individual) * neighbourhood) ) / FN # selection probability for each individual\n",
    "    return parents, fitness_sorted[:num_parents] # replace with actual fitness of chosen parents\n",
    "\n",
    "def c_max(individual):\n",
    "    for i in range(len(individual)/2, len(individual)): # find first and last assignment for each workstation\n",
    "        pass\n",
    "    pass\n",
    "\n",
    "def fitness_function(solution, solution_idx):\n",
    "    fitness = 0\n",
    "    if validate_sequence(solution, None) and validate_assignments(solution):\n",
    "        fitness = 1 / c_max(solution)\n",
    "        pass\n",
    "    else:\n",
    "        fitness = 0\n",
    "        pass\n",
    "    return fitness\n",
    "    pass\n",
    "\n",
    "def stage_1(): # GA for feasible solutions\n",
    "    num_generations = 1000\n",
    "    num_parents_mating = 50\n",
    "    sol_per_pop = 100\n",
    "    init_range_low = 0\n",
    "    init_range_high = len(orders) # doesn't really matter\n",
    "    keep_parents = 10\n",
    "    mutation_percent_genes = 10 # doesn't really matter\n",
    "\n",
    "    crossover_type = crossover_function\n",
    "    mutation_type = mutation_function\n",
    "    fitness_func = fitness_function\n",
    "    parent_selection_type = selection_function\n",
    "\n",
    "    num_genes = len(input_format) * 2\n",
    "    gene_type = int\n",
    "    gene_space = []\n",
    "\n",
    "    for i in range(int(num_genes / 2)):\n",
    "        # set space for the first half (assignments)\n",
    "        gene_space.append(n_workstations)\n",
    "    for i in range(int(num_genes / 2), num_genes):\n",
    "        # set space for the second half (sequence)\n",
    "        gene_space.append(len(orders))\n",
    "\n",
    "    ga_instance = pygad.GA(num_generations=num_generations, num_parents_mating=num_parents_mating, fitness_func=fitness_func, sol_per_pop=sol_per_pop, num_genes=num_genes, init_range_low=init_range_low, init_range_high=init_range_high, parent_selection_type=parent_selection_type, keep_parents=keep_parents, crossover_type=crossover_type, mutation_type=mutation_type, mutation_percent_genes=mutation_percent_genes, gene_type=gene_type, gene_space=gene_space)\n",
    "    ga_instance.run()\n",
    "    solution, solution_fitness, solution_idx = ga_instance.best_solution()\n",
    "    print(\"Parameters of the best solution : {solution}\".format(solution=solution))\n",
    "    print(\"Fitness value of the best solution = {solution_fitness}\".format(solution_fitness=abs(solution_fitness) - 1))\n",
    "    return ga_isntance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stage_2(population): # clustering of GA result population\n",
    "    clusters = []\n",
    "    for i in range(n_clusters):\n",
    "        clusters.append([]) # create clusters using indices\n",
    "    for i in range(len(solutions)):\n",
    "        pass\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_neighbours(individual):\n",
    "    # change position of an operation to alternative machine\n",
    "    # create new schedule sequence accordingly, create n solutions\n",
    "    pass\n",
    "\n",
    "def calculate_fitness(individual):\n",
    "    # rebuild schedule\n",
    "    # makespan only\n",
    "    pass\n",
    "\n",
    "def move_and_insert(individual):\n",
    "    pass\n",
    "\n",
    "def stage_3(clusters): # tabu search for best solution\n",
    "    best = individuals[0]\n",
    "    max_tabu_size = int(len(individuals) / 4) # for testing\n",
    "    best_candidate = individuals[0]\n",
    "    best_fitness = best_candidate_fitness = calculate_fitness(best_candidate)\n",
    "    tabu_list = []\n",
    "    tabu_list.append(individuals[0])\n",
    "    stop = False\n",
    "    max_iter = 1000\n",
    "    i = 0\n",
    "    while not stop:\n",
    "        neighbours = get_neighbours(best_candidate)\n",
    "        best_candidate = neighbours[0]\n",
    "        for candidate in neighbours:\n",
    "            if candidate not in tabu_list:\n",
    "                candidate_fitness = calculate_fitness(candidate)\n",
    "                if candidate_fitness < best_candidate_fitness:\n",
    "                    best_candidate = candidate\n",
    "                    best_candidate_fitness = candidate_fitness\n",
    "        if best_candidate_fitness < best_fitness:\n",
    "            best = best_candidate\n",
    "            best_fitness = best_candidate_fitness\n",
    "        tabu_list.append(best_candidate)\n",
    "        if len(tabu_list) > max_tabu_size:\n",
    "            tabu_list.pop()\n",
    "        stop = i >= max_iter\n",
    "        i+=1\n",
    "    return best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_population = stage_1()\n",
    "clusters = stage_2(end_population)\n",
    "solution = stage_3(clusters)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7f6a1dc8c4280d136ecdbc82017e55b6ce3aee96b85e53655c8afc2236474583"
  },
  "kernelspec": {
   "display_name": "Python 3.10.3 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
